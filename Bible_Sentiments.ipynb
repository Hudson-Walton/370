{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b35b1e-0e80-4c77-95d1-095c12157373",
   "metadata": {},
   "source": [
    "I was able to do most of this project with ease until I got to the last part of it. I feel good about getting sentiments with sia, but I could not figure out the error I was getting about Vader Lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d79f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Hudso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hudso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\Hudso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hudso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stoplist = stopwords.words('english')\n",
    "nltk.download(\"tagsets\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb45d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we open the file:\n",
    "# TYN is commented out because of errors in the text file, keeping it commented in the case that a use?fix is found for it it the future\n",
    "KJV_file = open('/Users/Hudso/OneDrive/Documents/GitHub/text-as-data/people/Bibledata/kjv.txt', 'r',encoding='utf-8')\n",
    "ASV_file = open('/Users/Hudso/OneDrive/Documents/GitHub/text-as-data/people/Bibledata/asv.txt', 'r',encoding='utf-8')\n",
    "WEB_file = open('/Users/Hudso/OneDrive/Documents/GitHub/text-as-data/people/Bibledata/web.txt', 'r',encoding='utf-8')\n",
    "NET_file = open('/Users/Hudso/OneDrive/Documents/GitHub/text-as-data/people/Bibledata/net.txt', 'r',encoding='utf-8')\n",
    "\n",
    "# Then we read the file:\n",
    "KJV = KJV_file.read()\n",
    "ASV = ASV_file.read()\n",
    "WEB = WEB_file.read()\n",
    "NET = NET_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41d350c2-db14-4ae9-b013-6e1e44d31331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine translations \n",
    "\n",
    "Bibles = (KJV + ASV + WEB + NET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d52ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up sia\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120210a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "KJV_Tokens = nltk.tokenize.word_tokenize(KJV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93d7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(KJV_Tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8cf547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.784, 'pos': 0.216, 'compound': 0.8481}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b49ecda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize into sentences\n",
    "\n",
    "KJV_sentences = sent_tokenize(KJV)\n",
    "\n",
    "Corpus_sentences = sent_tokenize(Bibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf55811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_KJV = []\n",
    "neg_KJV = []\n",
    "\n",
    "pos_Bible = []\n",
    "neg_Bible = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "168de1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos for KJV\n",
    "for sentence in KJV_sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract positive and negative words\n",
    "    for word, score in scores.items():\n",
    "        if score > 0:\n",
    "            pos_KJV.append(word)\n",
    "        elif score < 0:\n",
    "            neg_KJV.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de6f25f8-af13-47f8-92d2-a5a307e40def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos for Corpus\n",
    "\n",
    "for sentence in Corpus_sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract positive and negative words\n",
    "    for word, score in scores.items():\n",
    "        if score > 0:\n",
    "            pos_Bible.append(word)\n",
    "        elif score < 0:\n",
    "            neg_Bible.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f991c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neg', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neg', 'neu', 'pos', 'compound', 'neg', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neg', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound', 'neu', 'pos', 'compound']\n"
     ]
    }
   ],
   "source": [
    "print(pos_KJV[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8007844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will', 'ye', 'save', 'him', '?', 'will', 'ye', 'contend', 'for', 'God', '?', 'Blessed', '[', 'be', ']', 'God', '.', '5', 'And', 'they', 'have', 'rewarded', 'me', 'evil', 'for', 'good', ',', 'and', 'hatred', 'for', 'my', 'love', '.', 'Praise', 'the', 'LORD', '.', 'saith', 'thy', 'God', '.', '[', 'is', 'he', ']', 'a', 'pleasant', 'child', '?', 'is', 'their', 'wisdom', 'vanished', '?', 'we', 'shall', 'not', 'die', '.', 'who', 'can', 'forgive', 'sins', 'but', 'God', 'only', '?', 'Fare', 'ye', 'well', '.', 'I', 'praise', '[', 'you', ']', 'not', '.', 'God', 'knoweth', '.', '16', '¶', 'Rejoice', 'evermore', '.', 'can', 'faith', 'save', 'him', '?', 'let', 'him', 'pray', '.', 'Is', 'any', 'merry', '?', 'Love']\n"
     ]
    }
   ],
   "source": [
    "#Getting positive words for KJV\n",
    "pos_words_KJV = []\n",
    "\n",
    "for sentence in KJV_sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract words contributing to positive sentiment\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if scores['pos'] > scores['neg']:  # Check if the sentence has positive sentiment\n",
    "            if scores['pos'] > scores['neu'] and scores['pos'] > scores['compound']:\n",
    "                pos_words_KJV.append(word)  # Append the word to the positive_words list\n",
    "                \n",
    "print(pos_words_KJV[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f1dcc6b-9cdf-4812-8f4d-d7cd09950973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will', 'ye', 'save', 'him', '?', 'will', 'ye', 'contend', 'for', 'God', '?', 'Blessed', '[', 'be', ']', 'God', '.', '5', 'And', 'they', 'have', 'rewarded', 'me', 'evil', 'for', 'good', ',', 'and', 'hatred', 'for', 'my', 'love', '.', 'Praise', 'the', 'LORD', '.', 'saith', 'thy', 'God', '.', '[', 'is', 'he', ']', 'a', 'pleasant', 'child', '?', 'is', 'their', 'wisdom', 'vanished', '?', 'we', 'shall', 'not', 'die', '.', 'who', 'can', 'forgive', 'sins', 'but', 'God', 'only', '?', 'Fare', 'ye', 'well', '.', 'I', 'praise', '[', 'you', ']', 'not', '.', 'God', 'knoweth', '.', '16', '¶', 'Rejoice', 'evermore', '.', 'can', 'faith', 'save', 'him', '?', 'let', 'him', 'pray', '.', 'Is', 'any', 'merry', '?', 'Love']\n"
     ]
    }
   ],
   "source": [
    "# Getting positive words for corpus\n",
    "\n",
    "pos_words_Bible = []\n",
    "\n",
    "for sentence in Corpus_Sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract words contributing to positive sentiment\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if scores['pos'] > scores['neg']:  # Check if the sentence has positive sentiment\n",
    "            if scores['pos'] > scores['neu'] and scores['pos'] > scores['compound']:\n",
    "                pos_words_Bible.append(word)  # Append the word to the positive_words list\n",
    "                \n",
    "print(pos_words_Bible[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1311f413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bury', 'therefore', 'thy', 'dead', '.', 'If', 'I', 'be', 'bereaved', '[', 'of', 'my', 'children', ']', ',', 'I', 'am', 'bereaved', '.', '18', 'Or', '[', 'if', ']', 'he', 'smite', 'him', 'with', 'an', 'hand', 'weapon', 'of', 'wood', ',', 'wherewith', 'he', 'may', 'die', ',', 'and', 'he', 'die', ',', 'he', '[', 'is', ']', 'a', 'murderer', ':', 'the', 'murderer', 'shall', 'surely', 'be', 'put', 'to', 'death', '.', '16', 'They', 'provoked', 'him', 'to', 'jealousy', 'with', 'strange', '[', 'gods', ']', ',', 'with', 'abominations', 'provoked', 'they', 'him', 'to', 'anger', '.', 'So', 'he', 'died', '.', '8', 'Woe', 'unto', 'us', '!', 'whom', 'have', 'I', 'oppressed', '?', 'after', 'a', 'dead', 'dog', ',', 'after', 'a']\n"
     ]
    }
   ],
   "source": [
    "#Gettign negative words for corpus\n",
    "neg_words_KJV = []\n",
    "\n",
    "# Iterate over each sentence in your corpus\n",
    "for sentence in KJV_sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract words contributing to negative sentiment\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if scores['neg'] > scores['pos']:  # Check if the sentence has negative sentiment\n",
    "            if scores['neg'] > scores['neu'] and scores['neg'] > scores['compound']:\n",
    "                neg_words_KJV.append(word)  # Append the word to the negative_words list\n",
    "\n",
    "# Print the list of negative words\n",
    "print(neg_words_KJV[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c9d0f1-553b-48a6-bd73-e459a289efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bury', 'therefore', 'thy', 'dead', '.', 'If', 'I', 'be', 'bereaved', '[', 'of', 'my', 'children', ']', ',', 'I', 'am', 'bereaved', '.', '18', 'Or', '[', 'if', ']', 'he', 'smite', 'him', 'with', 'an', 'hand', 'weapon', 'of', 'wood', ',', 'wherewith', 'he', 'may', 'die', ',', 'and', 'he', 'die', ',', 'he', '[', 'is', ']', 'a', 'murderer', ':', 'the', 'murderer', 'shall', 'surely', 'be', 'put', 'to', 'death', '.', '16', 'They', 'provoked', 'him', 'to', 'jealousy', 'with', 'strange', '[', 'gods', ']', ',', 'with', 'abominations', 'provoked', 'they', 'him', 'to', 'anger', '.', 'So', 'he', 'died', '.', '8', 'Woe', 'unto', 'us', '!', 'whom', 'have', 'I', 'oppressed', '?', 'after', 'a', 'dead', 'dog', ',', 'after', 'a']\n"
     ]
    }
   ],
   "source": [
    "# Getting negative words for Bible\n",
    "\n",
    "neg_words_Bible = []\n",
    "\n",
    "# Iterate over each sentence in your corpus\n",
    "for sentence in Corpus_Sentences:\n",
    "    # Get sentiment scores from VADER\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    # Extract words contributing to negative sentiment\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if scores['neg'] > scores['pos']:  # Check if the sentence has negative sentiment\n",
    "            if scores['neg'] > scores['neu'] and scores['neg'] > scores['compound']:\n",
    "                neg_words_Bible.append(word)  # Append the word to the negative_words list\n",
    "\n",
    "# Print the list of negative words\n",
    "print(neg_words_Bible[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeeaa4df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vader_lexicon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m negative_similar_words \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m pos_words_KJV:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vader_lexicon:\n\u001b[0;32m      7\u001b[0m         similar_words \u001b[38;5;241m=\u001b[39m word_embedding_model\u001b[38;5;241m.\u001b[39mmost_similar(word)\n\u001b[0;32m      8\u001b[0m         positive_similar_words\u001b[38;5;241m.\u001b[39mextend([similar_word[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m similar_word \u001b[38;5;129;01min\u001b[39;00m similar_words])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vader_lexicon' is not defined"
     ]
    }
   ],
   "source": [
    "# Start finding similiar words\n",
    "positive_similar_words = []\n",
    "negative_similar_words = []\n",
    "\n",
    "for word in pos_words_KJV:\n",
    "    if word not in vader_lexicon:\n",
    "        similar_words = word_embedding_model.most_similar(word)\n",
    "        positive_similar_words.extend([similar_word[0] for similar_word in similar_words])\n",
    "\n",
    "for word in neg_words_KJV:\n",
    "    if word not in vader_lexicon:\n",
    "        similar_words = word_embedding_model.most_similar(word)\n",
    "        negative_similar_words.extend([similar_word[0] for similar_word in similar_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b8229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c4a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
